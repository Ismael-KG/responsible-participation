# What is responsible participation in data science and AI?

###### tags: `SIG`, `collaborative writing`

:::info
This is an open, work-in-progress blog post, being produced as part of the 'facilitating responsible participation in data science' interest group. 

If you are interested in contributing, please contact cburr@turing.ac.uk
:::

## Introduction

The French philosopher, Emmanuel Levinas, argued that ethical commitments and responsibilities arise in the face-to-face encounters and relations of human sociality. It is the human face specificially, he claimed, that "orders and ordains" us, by forcing us to recognise the Other. 

Levinas' claim raises an important and pressing question about the extent to which the processes and activities, which characterise the typical development of complex data-driven technologies, serve to close us off from those face-to-face encounters and interpersonal relations that he argued ground our ethical commitments to one another. 

Recent work in data ethics and AI ethics has attempted to distil aspects of these ethical commitments into over-arching principles and guidelines, and to then attempt to "operationalise" said principles into practical tools, such as fairness optimisation metrics. However, the *devil is in the details* when it comes to how ethical principles are specified, and how they can guide practical action or decision-making. 

(Example)

Therefore, what we need is something that can begin to ground this work in a genuine commitment to open dialogue and public reason, and the interconnected social and organisational *practices* that ought to underpin responsible research and innovation. This is necessary to enable and empower those involved or affected by the design, development, and deployment of data-driven technologies to care about and contribute to the formation of a genuinely inclusive vision of how technology can be used to support the common good. 

The following schematic can help us to illustrate how the myriad roles and responsibilities implicated within a project's lifecycle intersect with and interweave through its various stages and activities.

![Figure 1 - An overview of a typical project lifecycle, split into three over-arching stages of (project) design, (model) development, and (system) deployment, and furthe broken into representative sub-stages. ](https://i.imgur.com/KDI6CPY.png)

The schematic breaks a typical project lifecycle for some data-driven technology into three components: project design, model development, and system deployment. Or, more simply, design, development, and deployment. 

Although it is an abstraction, it is almost invariably true that the work involved throughout these stages is a multi-person (or multi-team) task, due to the wide-ranging set of skills and capabilities that are required. However, the way such roles and responsibilities are often defined at an organisational or institutional level (e.g. in job specifications) tend to reflect the practical demands of organisational efficiency, rather than the normative demands of ethical and responsible project governance. 

In reality, the individual job roles and responsibilities, which are implicated in the governance of complex projects, are interwoven to such an extent that they form an inextricable Gordian Knot of collective responsibility. Moreover, some of the skills may fall outside of a single team's remit, requiring the co-operation of several organisations. 

The above schematic, therefore, serves as a *starting point* for demonstrating how responsible participation in research and innovation requires all team members and stakeholders to reflectively deliberate about how their own roles and responsibilities intersect or impact upon the various stages of the project lifecycle. 

Let's see how it can support a process of reflection and deliberation by exploring the concept of missing data.

## Responsible Participation in Project Design: The Problem of Missing Data

(Drafting)